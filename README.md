# 基于视觉的机械臂抓取

## 工作原理:
连接机械臂和相机，通过相机拍摄物体，利用深度学习模型检测目标物体，计算物体的质心，然后将质心转换到机器人坐标系下，机器人移动到质心位置进行抓取。

## 结果展示：
图1 - 深度相机图（左：Gemini2，中：ZED2i，右：识别结果）

![图1.png](attachment:图1.png)

图2 - 机械臂抓取物体效果图（基于ZED2i + DeepLabV3Plus-ResNet18）

![图2.gif](attachment:图2.gif)

## 硬件部分：
Orbbec Gemini2深度相机 - 双目红外结构光
Stereolabs ZED2i深度相机 - 双目RGB
Hans Robot Elfin机械臂 - 6自由度

## 代码部分: 
### 1. 机械臂控制函数：Hans_Robot.py 
- 封装了常用的机械臂控制函数：
1. 机器人参数初始化：
    1.1 连接参数：IP和端口、电箱ID、机器人ID、末端执行器ID、是否使用末端执行器、是否使用相机
    1.2 工作参数：工作空间限制、关节限制、最大速度、最大加速度、TCP坐标、机器人速度比例
    1.3 运动参数：位置容差阈值、回零位置、放置位置、抓取位姿
    1.4 相机参数：相机内参、相机深度尺度
2. 机器人基础函数 - 连接、使能、下电、回零、停止、暂停、继续、复位
3. 机器人工具函数 - 列表字符串转浮点数、弧度转角度、角度转弧度
4. 机器人功能函数 - 启动机器人、重启机器人、获取相机数据、末端执行器检测、末端执行器打开、末端执行器闭合、机器人运动速度设置、机器人运动状态检测、机器人当前状态检测、机器人当前位置获取、机器人移动精度检测、判断机器人是否在工作空间内
5. 机器人运动函数 - 关节点动调节、直线点动调节、路点点动调节、关节运动、直线轨迹运动、圆弧轨迹运动、机器人高精度移动函数
6. 机器人抓取函数 - 机器人平面抓取物体、机器人抓取放置物体、机器人推动物体

### 2. 深度相机函数：Gemini_camera.py | Gemini_photo.py | ZED2i_camera.py | ZED2i_photo.py
- camera.py为相机初始化和连接函数，photo.py为图像显示、拍照和保存函数
1. 相机参数初始化 - 确定相机设备ID、RGB图像尺寸、RGB图像帧率、深度图像尺寸、深度图像帧率，初始化RGB内参、深度图内参、深度缩放系数
2. 相机连接 - 配置相机参数、获取相机数据流，确定对齐模式、深度尺度、相机内参，打印相机数据流信息
3. 相机功能函数 - 深度模式选择，开关激光，开关LDP，开关软件滤波，获取相机内参（输出为特定格式），获取RGB图像和深度图像，保存图像
4. 相机图像显示 - RGB与深度图像叠加显示、RGB与深度图像独立显示
5. 相机工具函数 - OpenCV窗口的回调函数，深度图像修复缺失值，深度图像归一化

### 3. 目标检测算法（语义/实例分割）：InstanceSegmentation
|模型|预测精度（IoU）|每秒预测帧率|
|-|-:|-:|
UNet|0.9085|37.42 ± 1.33
UNetPlus|0.8933|41.81 ± 2.73
NestedUNet|0.9093|38.67 ± 2.54
U2Net|0.9132|27.84 ± 0.18
DeepLabV3Plus-ResNet18|0.9127|36.54 ± 0.11
DeepLabV3Plus-ResNet34|0.9080|30.32 ± 1.44
MedicalTransformer|0.8968|14.23 ± 0.09

### 4. 官方 SKD 文件：utils
